# MicroBERT 版本对比

本文档详细对比了MicroBERT的各个版本，帮助你选择最适合的版本。

## 📊 版本概览

| **版本** | **目标** | **模型大小** | **内存需求** | **训练时间** | **适用场景** |
|----------|----------|--------------|--------------|--------------|--------------|
| **v1** | 快速入门 | 2L/2H/4D (小) | 低 | ~5分钟 | 学习、测试 |
| **v2** | 标准训练 | 4L/4H/8D (中) | 中等 | ~30分钟 | 标准训练 |
| **v3** | 多GPU训练 | 6L/8H/16D (中) | 中等 | ~15分钟 | 多GPU环境 |
| **v4** | 24GB优化 | 4-6L/8H/128D (中) | 中等 | ~15分钟 | 24GB+ GPU |

## 🔍 详细对比

### **v1: 快速入门版本**

**特点**：
- 最小的模型配置，适合快速验证和学习
- 使用IMDB数据集，数据量小
- 单GPU训练，内存需求低

**配置**：
```python
# 模型配置
n_layers = 2
n_heads = 2
n_embed = 4
max_seq_len = 128
vocab_size = 10000

# 训练配置
batch_size = 32
epochs = 3
learning_rate = 5e-5
```

**适用场景**：
- 学习BERT原理
- 快速测试和验证
- 资源受限环境

### **v2: 标准训练版本**

**特点**：
- 中等模型配置，平衡性能和效率
- 支持多种数据集（IMDB、Hugging Face）
- 支持流式数据处理

**配置**：
```python
# 模型配置 (HF数据集)
n_layers = 4
n_heads = 4
n_embed = 8
max_seq_len = 128
vocab_size = 10000

# 训练配置
batch_size = 32
epochs = 5
learning_rate = 3e-5
```

**适用场景**：
- 标准训练任务
- 中等规模数据集
- 单GPU或小规模多GPU

### **v3: 多GPU训练版本**

**特点**：
- 针对多GPU环境优化
- 支持分布式训练
- 中等模型配置

**配置**：
```python
# 模型配置 (HF数据集)
n_layers = 6
n_heads = 8
n_embed = 16
max_seq_len = 128
vocab_size = 10000

# 训练配置
batch_size = 32 (per GPU)
epochs = 5
learning_rate = 3e-5
```

**适用场景**：
- 多GPU训练环境
- 大规模数据集
- 生产环境训练

### **v4: 24GB内存优化版本**

**特点**：
- 针对24GB GPU内存优化
- 动态配置，根据GPU内存自动调整
- H200/A10兼容，确保内存使用不超过24GB

**配置**：
```python
# 模型配置 (HF数据集) - 动态调整
# 大模型 (100GB+ GPU): 4层, 8头, 128维嵌入, batch_size=16
# 中等模型 (40GB+ GPU): 6层, 8头, 128维嵌入, batch_size=32  
# 小模型 (24GB GPU): 4层, 8头, 128维嵌入, batch_size=8

n_layers = 4-6 (动态)
n_heads = 8
n_embed = 128
max_seq_len = 128 (减少内存使用)
vocab_size = 50000 (限制)

# 训练配置
batch_size = 8-32 (动态调整)
epochs = 5
learning_rate = 3e-5
```

**适用场景**：
- 24GB+ GPU (H200, A10, RTX 4090等)
- 确保内存使用不超过24GB
- 大规模模型训练

## 🎯 选择指南

### **按硬件配置选择**

| **GPU内存** | **推荐版本** | **理由** |
|-------------|--------------|----------|
| < 8GB | v1 | 内存需求最低，适合入门 |
| 8-16GB | v2 | 平衡性能和内存使用 |
| 16-24GB | v3 | 多GPU优化，中等模型 |
| 24GB+ | v4 | 充分利用GPU内存 |

### **按使用场景选择**

| **场景** | **推荐版本** | **理由** |
|----------|--------------|----------|
| 学习/测试 | v1 | 快速验证，资源需求低 |
| 标准训练 | v2 | 平衡性能和效率 |
| 多GPU训练 | v3 | 分布式训练优化 |
| 生产环境 | v4 | 高内存利用率，大模型 |

### **按数据集大小选择**

| **数据集大小** | **推荐版本** | **理由** |
|----------------|--------------|----------|
| < 100K | v1/v2 | 小数据集，快速训练 |
| 100K-1M | v2/v3 | 中等数据集，标准训练 |
| 1M-10M | v3/v4 | 大数据集，多GPU优化 |
| > 10M | v4 | 超大数据集，高内存利用率 |

## 🚀 性能对比

### **训练时间对比** (8GPU环境)

| **版本** | **500K样本** | **5M样本** | **10M样本** |
|----------|--------------|------------|-------------|
| v1 | ~2分钟 | ~20分钟 | ~40分钟 |
| v2 | ~5分钟 | ~50分钟 | ~100分钟 |
| v3 | ~15分钟 | ~1.3小时 | ~2.6小时 |
| v4 | ~10分钟 | ~1小时 | ~1.7小时 |

### **内存使用对比**

| **版本** | **单GPU内存** | **8GPU总内存** | **利用率** |
|----------|---------------|----------------|------------|
| v1 | ~2GB | ~16GB | 低 |
| v2 | ~4GB | ~32GB | 中等 |
| v3 | ~6GB | ~48GB | 中等 |
| v4 | ~20GB | ~160GB | 高 |

## 📝 迁移指南

### **从v3升级到v4**

1. **更新脚本**：
   ```bash
   # 从v3脚本
   ./train_h200_8gpu_standard.sh
   
   # 升级到v4脚本
   ./train_h200_8gpu_v4.sh
   ```

2. **更新代码**：
   ```bash
   # 从v3代码
   python mlm_pretrain_v3.py
   
   # 升级到v4代码
   python mlm_pretrain_v4.py
   ```

3. **配置调整**：
   - 批次大小：32 → 96
   - 序列长度：128 → 256
   - 词汇表大小：10K → 25K
   - 模型大小：6L/8H/16D → 8L/8H/256D

### **从v2升级到v3**

1. **环境准备**：
   - 确保多GPU环境
   - 安装分布式训练依赖

2. **脚本更新**：
   ```bash
   # 从v2代码
   python mlm_pretrain_v2.py
   
   # 升级到v3代码
   torchrun --nproc_per_node=8 mlm_pretrain_v3.py
   ```

## 🔧 自定义配置

### **调整模型大小**

```python
# 在对应版本的代码中修改
n_layers = 8      # 层数
n_heads = 8       # 注意力头数
n_embed = 256     # 嵌入维度
max_seq_len = 256 # 序列长度
```

### **调整批次大小**

```bash
# 在训练脚本中修改
BATCH_SIZE_PER_GPU=96  # 每GPU批次大小
```

### **调整数据量**

```bash
# 在训练脚本中修改
MAX_SAMPLES="10M"  # 数据样本数量
```

## 📞 技术支持

如果你在选择版本时遇到问题，请参考：

1. **硬件要求**：检查GPU内存和数量
2. **性能需求**：根据训练时间要求选择
3. **数据规模**：根据数据集大小选择
4. **使用场景**：根据具体应用场景选择

选择合适的版本是成功训练的关键！
